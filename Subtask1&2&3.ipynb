{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fitting-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "color-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import smart_open\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from math import log\n",
    "from numpy.random import default_rng, rand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "latter-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../dataset/passage_collection_new.txt\", 'r', encoding = 'utf-8') \n",
    "document = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "disturbed-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = [\"qid\", \"pid\", \"query\", \"passage\"]\n",
    "candidate_passages_top1000 = pd.read_csv(\"../dataset/candidate_passages_top1000.tsv\", sep='\\t', names=header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ordinary-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = [\"qid\", \"query\"]\n",
    "test_queries = pd.read_csv(\"../dataset/test-queries.tsv\", sep='\\t', names=header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "reserved-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../part2/train_data.tsv\", sep='\\t')\n",
    "validation_data = pd.read_csv(\"../part2/validation_data.tsv\", sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "absent-colorado",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>queries</th>\n",
       "      <th>passage</th>\n",
       "      <th>relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188714</td>\n",
       "      <td>1000052</td>\n",
       "      <td>foods and supplements to lower blood sugar</td>\n",
       "      <td>Watch portion sizes: ■ Even healthy foods will...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>995526</td>\n",
       "      <td>1000094</td>\n",
       "      <td>where is the federal penitentiary in ind</td>\n",
       "      <td>It takes THOUSANDS of Macy's associates to bri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660957</td>\n",
       "      <td>1000115</td>\n",
       "      <td>what foods are good if you have gout?</td>\n",
       "      <td>The good news is that you will discover what g...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>837202</td>\n",
       "      <td>1000252</td>\n",
       "      <td>what is the nutritional value of oatmeal</td>\n",
       "      <td>Oats make an easy, balanced breakfast. One cup...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130825</td>\n",
       "      <td>1000268</td>\n",
       "      <td>definition for daring</td>\n",
       "      <td>Such a requirement would have three desirable ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>408149</td>\n",
       "      <td>1000288</td>\n",
       "      <td>is dhgate a scam</td>\n",
       "      <td>If you think you ve been targeted by a counter...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1019649</td>\n",
       "      <td>1000419</td>\n",
       "      <td>what study for mets to brain</td>\n",
       "      <td>Sorry he's having so much pain. The reason tha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1099065</td>\n",
       "      <td>1000436</td>\n",
       "      <td>how far deep to plant beet early wonder</td>\n",
       "      <td>The simplest way, and my preference, is to roa...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1084910</td>\n",
       "      <td>1000466</td>\n",
       "      <td>what disease do roof rats cause</td>\n",
       "      <td>1 A cage trap baited with peanut butter or a s...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>959083</td>\n",
       "      <td>1000479</td>\n",
       "      <td>when was niagara falls created</td>\n",
       "      <td>Bulbar Onset – ALS. ALS is like Niagara Falls,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid      pid                                     queries  \\\n",
       "0   188714  1000052  foods and supplements to lower blood sugar   \n",
       "1   995526  1000094    where is the federal penitentiary in ind   \n",
       "2   660957  1000115       what foods are good if you have gout?   \n",
       "3   837202  1000252    what is the nutritional value of oatmeal   \n",
       "4   130825  1000268                       definition for daring   \n",
       "5   408149  1000288                            is dhgate a scam   \n",
       "6  1019649  1000419                what study for mets to brain   \n",
       "7  1099065  1000436     how far deep to plant beet early wonder   \n",
       "8  1084910  1000466             what disease do roof rats cause   \n",
       "9   959083  1000479              when was niagara falls created   \n",
       "\n",
       "                                             passage  relevancy  \n",
       "0  Watch portion sizes: ■ Even healthy foods will...        0.0  \n",
       "1  It takes THOUSANDS of Macy's associates to bri...        0.0  \n",
       "2  The good news is that you will discover what g...        0.0  \n",
       "3  Oats make an easy, balanced breakfast. One cup...        0.0  \n",
       "4  Such a requirement would have three desirable ...        0.0  \n",
       "5  If you think you ve been targeted by a counter...        0.0  \n",
       "6  Sorry he's having so much pain. The reason tha...        0.0  \n",
       "7  The simplest way, and my preference, is to roa...        0.0  \n",
       "8  1 A cage trap baited with peanut butter or a s...        0.0  \n",
       "9  Bulbar Onset – ALS. ALS is like Niagara Falls,...        0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aerial-representative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4364339, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "olive-breathing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>queries</th>\n",
       "      <th>passage</th>\n",
       "      <th>relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1082792</td>\n",
       "      <td>1000084</td>\n",
       "      <td>what does the golgi apparatus do to the protei...</td>\n",
       "      <td>Start studying Bonding, Carbs, Proteins, Lipid...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>995825</td>\n",
       "      <td>1000492</td>\n",
       "      <td>where is the graphic card located in the cpu</td>\n",
       "      <td>For example, a “PC Expansion Card” maybe the j...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>995825</td>\n",
       "      <td>1000494</td>\n",
       "      <td>where is the graphic card located in the cpu</td>\n",
       "      <td>The Common Cards &amp; Buses. The most common type...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1091246</td>\n",
       "      <td>1000522</td>\n",
       "      <td>property premises meaning</td>\n",
       "      <td>The occurrence of since tells us that the firs...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1047854</td>\n",
       "      <td>1000585</td>\n",
       "      <td>what is printing mechanism</td>\n",
       "      <td>Windows desktop applications Develop Desktop t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>991832</td>\n",
       "      <td>1000599</td>\n",
       "      <td>who discovered the element carbon</td>\n",
       "      <td>1. 1  a nonmetallic element existing in the th...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>185299</td>\n",
       "      <td>1000647</td>\n",
       "      <td>fastest cell phone processor</td>\n",
       "      <td>Tips for calling a cell phone in Greece: To ca...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>574730</td>\n",
       "      <td>1000663</td>\n",
       "      <td>what are the three monetary policy tools of th...</td>\n",
       "      <td>Federal Reserve updates including rates, news ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1085008</td>\n",
       "      <td>1000675</td>\n",
       "      <td>what did maria theresa do for the serfs</td>\n",
       "      <td>In this feudal system, the king awarded land g...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>609628</td>\n",
       "      <td>1000771</td>\n",
       "      <td>what county is mitchell south dakota in</td>\n",
       "      <td>South Dakota: According to our research of Sou...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       qid      pid                                            queries  \\\n",
       "0  1082792  1000084  what does the golgi apparatus do to the protei...   \n",
       "1   995825  1000492       where is the graphic card located in the cpu   \n",
       "2   995825  1000494       where is the graphic card located in the cpu   \n",
       "3  1091246  1000522                          property premises meaning   \n",
       "4  1047854  1000585                         what is printing mechanism   \n",
       "5   991832  1000599                  who discovered the element carbon   \n",
       "6   185299  1000647                       fastest cell phone processor   \n",
       "7   574730  1000663  what are the three monetary policy tools of th...   \n",
       "8  1085008  1000675            what did maria theresa do for the serfs   \n",
       "9   609628  1000771            what county is mitchell south dakota in   \n",
       "\n",
       "                                             passage  relevancy  \n",
       "0  Start studying Bonding, Carbs, Proteins, Lipid...        0.0  \n",
       "1  For example, a “PC Expansion Card” maybe the j...        0.0  \n",
       "2  The Common Cards & Buses. The most common type...        0.0  \n",
       "3  The occurrence of since tells us that the firs...        0.0  \n",
       "4  Windows desktop applications Develop Desktop t...        0.0  \n",
       "5  1. 1  a nonmetallic element existing in the th...        0.0  \n",
       "6  Tips for calling a cell phone in Greece: To ca...        0.0  \n",
       "7  Federal Reserve updates including rates, news ...        0.0  \n",
       "8  In this feudal system, the king awarded land g...        0.0  \n",
       "9  South Dakota: According to our research of Sou...        0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "minute-ballet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103039, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n",
    "validation_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-lodging",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "negative-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(tokens):\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        new_token = re.sub(r'[^\\w\\s]', '', token)\n",
    "        if new_token != '':\n",
    "            new_tokens.append(new_token)\n",
    "    return new_tokens\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    new_tokens = []\n",
    "    stopword_set = set(stopwords.words('english'))\n",
    "    for token in tokens:\n",
    "        if token not in stopword_set:\n",
    "            new_tokens.append(token)\n",
    "    return new_tokens\n",
    "\n",
    "def lemmatize_verbs(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    root_words = []\n",
    "    for token in tokens:\n",
    "        root_word = lemmatizer.lemmatize(token, pos='v')\n",
    "#         root_word = lemmatizer.lemmatize(token, pos='n')\n",
    "#         root_word = lemmatizer.lemmatize(token, pos='a')\n",
    "        root_words.append(root_word)\n",
    "    return root_words\n",
    "\n",
    "def remove_numbers(tokens):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.isdigit():\n",
    "            pass\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "    return new_tokens\n",
    "\n",
    "def preprocessing(passage):\n",
    "    passage = passage.lower()\n",
    "    tokens = nltk.word_tokenize(passage)\n",
    "    tokens = remove_punctuation(tokens)\n",
    "    tokens = remove_stopwords(tokens)\n",
    "    tokens = lemmatize_verbs(tokens)\n",
    "    tokens = remove_numbers(tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-grenada",
   "metadata": {},
   "source": [
    "# Subtask 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "young-peeing",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dominant-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_no_dup_passages = validation_data.drop_duplicates(subset=['pid'], inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atlantic-sussex",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(955211, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation_data_no_dup_passages.head(20)\n",
    "validation_data_no_dup_passages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rural-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_passage_average_length_and_total_word_occurences_corpus():\n",
    "    number_of_passages = len(validation_data_no_dup_passages)\n",
    "    count_total_length = 0\n",
    "    for idx, row in validation_data_no_dup_passages.iterrows():\n",
    "        count_total_length += len(preprocessing(row['passage']))\n",
    "    return count_total_length, count_total_length/number_of_passages \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "thorough-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_word_occurences, avdl = get_passage_average_length_and_total_word_occurences_corpus()\n",
    "total_word_occurences = 30757932\n",
    "avdl = 32.200144261320276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "japanese-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_word_occurences\n",
    "# avdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lightweight-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "k1 = 1.2\n",
    "k2 = 100\n",
    "b = 0.75\n",
    "R = 0\n",
    "r = 0\n",
    "N = len(validation_data_no_dup_passages)\n",
    "\n",
    "def K_cal(dl):\n",
    "    return k1 * ((1-b) + b * (float(dl)/float(avdl)) )\n",
    "\n",
    "\n",
    "def BM25_cal(query, passage):\n",
    "    query_tokens = preprocessing(query)\n",
    "    passage_tokens = preprocessing(passage)\n",
    "    query_length = len(query_tokens)\n",
    "    query_token_freq_dict = nltk.FreqDist(query_tokens)\n",
    "    passage_token_freq_dict = nltk.FreqDist(passage_tokens)\n",
    "    dl = len(passage_tokens)\n",
    "    K = K_cal(dl)\n",
    "    score = 0\n",
    "    for token in query_tokens:\n",
    "        try:\n",
    "            n = len(inverted_index[token])\n",
    "        except:\n",
    "            n = 0\n",
    "        f = passage_token_freq_dict[token]\n",
    "        qf = query_token_freq_dict[token]\n",
    "        first_term = log( ( (r + 0.5) / (R - r + 0.5) ) / ( (n - r + 0.5) / (N - n - R + r + 0.5)) )\n",
    "        second_term = ((k1 + 1) * f) / (K + f)\n",
    "        third_term = ((k2+1) * qf) / (k2 + qf)\n",
    "        score += first_term * second_term * third_term\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "accompanied-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_rankings = []\n",
    "for idx, row in validation_data.iterrows():\n",
    "#     print('count:', idx+1)\n",
    "    query = row['queries']\n",
    "    passage = row['passage']\n",
    "    bm25_rankings.append(BM25_cal(query, passage))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "coastal-winter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 218534, 1076853,   95986,   95987,  831065,  725920,  504442,\n",
       "        654647,  341262,  281695,  950916,  586050,  871938,  793356,\n",
       "        944762,  714508,  900185,  206973,  629358,  701682,  248618,\n",
       "        259324,  702792,  286327,  205094,   98221,  519566,  242694,\n",
       "        705667,  922032,  197484,  431189,  419681,  237993,  502543,\n",
       "        793493,  646679,  559150,  303774,  638714,  778563,  155707,\n",
       "         45281,  132857,  213755,  299424,  252540,    9338, 1075869,\n",
       "        139233,  733889,  401291,  373812,  784890, 1008311,  911301,\n",
       "        909449,  558879,  857483,  602553,  171827,  217514,  857646,\n",
       "        539660,  195886, 1078616,  554316,  872234,  346989,   28250,\n",
       "       1026344,  330458, 1026153,  612051,  395691,  530538,  313678,\n",
       "        693646,  175037,  751525,  216400,  663797,   99840,  928996,\n",
       "          5558,  428329,  546185,   46827,  112665,  118094,  752555,\n",
       "       1017110,  455444,  910607,  648719,  793681, 1063650,  212436,\n",
       "        415429,  654277], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_k = 100\n",
    "results_bm25 = np.array(bm25_rankings).argsort()[-ranking_k:][::-1]\n",
    "results_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beautiful-joyce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>queries</th>\n",
       "      <th>passage</th>\n",
       "      <th>relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218534</th>\n",
       "      <td>1007691</td>\n",
       "      <td>7251254</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>Direct method allocates each service departmen...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076853</th>\n",
       "      <td>1007691</td>\n",
       "      <td>7251259</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>The direct method is the most widely-used meth...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95986</th>\n",
       "      <td>1007691</td>\n",
       "      <td>7251251</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>service department provides a large amount of ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95987</th>\n",
       "      <td>1007691</td>\n",
       "      <td>7251253</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>The rows sum to 100%, so that all services pro...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831065</th>\n",
       "      <td>1007691</td>\n",
       "      <td>7251255</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>The most defensible sequence is to start with ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793681</th>\n",
       "      <td>1007691</td>\n",
       "      <td>4814576</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>Service Members | Veterans | Both. Military On...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063650</th>\n",
       "      <td>1007691</td>\n",
       "      <td>6395207</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>that hospital emergency department services ar...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212436</th>\n",
       "      <td>1007691</td>\n",
       "      <td>6872353</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>Yelp Customer Service customer service phone n...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415429</th>\n",
       "      <td>1007691</td>\n",
       "      <td>4114248</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>A service fee, service charge, or surcharge is...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654277</th>\n",
       "      <td>1007691</td>\n",
       "      <td>3743546</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>A Sub-contractor is liable to pay Service Tax ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qid      pid                                            queries  \\\n",
       "218534   1007691  7251254  when allocating service department costs, the ...   \n",
       "1076853  1007691  7251259  when allocating service department costs, the ...   \n",
       "95986    1007691  7251251  when allocating service department costs, the ...   \n",
       "95987    1007691  7251253  when allocating service department costs, the ...   \n",
       "831065   1007691  7251255  when allocating service department costs, the ...   \n",
       "...          ...      ...                                                ...   \n",
       "793681   1007691  4814576  when allocating service department costs, the ...   \n",
       "1063650  1007691  6395207  when allocating service department costs, the ...   \n",
       "212436   1007691  6872353  when allocating service department costs, the ...   \n",
       "415429   1007691  4114248  when allocating service department costs, the ...   \n",
       "654277   1007691  3743546  when allocating service department costs, the ...   \n",
       "\n",
       "                                                   passage  relevancy  \n",
       "218534   Direct method allocates each service departmen...        1.0  \n",
       "1076853  The direct method is the most widely-used meth...        0.0  \n",
       "95986    service department provides a large amount of ...        0.0  \n",
       "95987    The rows sum to 100%, so that all services pro...        0.0  \n",
       "831065   The most defensible sequence is to start with ...        0.0  \n",
       "...                                                    ...        ...  \n",
       "793681   Service Members | Veterans | Both. Military On...        0.0  \n",
       "1063650  that hospital emergency department services ar...        0.0  \n",
       "212436   Yelp Customer Service customer service phone n...        0.0  \n",
       "415429   A service fee, service charge, or surcharge is...        0.0  \n",
       "654277   A Sub-contractor is liable to pay Service Tax ...        0.0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_list_df = validation_data.loc[results_bm25]\n",
    "ranking_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "radical-foundation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>queries</th>\n",
       "      <th>passage</th>\n",
       "      <th>relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [qid, pid, queries, passage, relevancy]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data[(validation_data['relevancy'] < 1.0) & (validation_data['relevancy'] > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "established-greece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision_cal(ranking_list_df):\n",
    "    ranking_list_df = ranking_list_df.reset_index(drop=True, inplace=False)\n",
    "    total_relevant_retrieved = 0\n",
    "    precision_sum = 0\n",
    "    for idx, row in ranking_list_df.iterrows():\n",
    "        relevancy = row['relevancy']\n",
    "        if (relevancy):\n",
    "            isRelevant = True\n",
    "            total_relevant_retrieved += 1\n",
    "        precision = total_relevant_retrieved / (idx + 1)\n",
    "        precision_sum += precision\n",
    "    result = precision_sum / len(ranking_list_df)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adverse-myrtle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07445786781310981"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_cal(ranking_list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acknowledged-touch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>queries</th>\n",
       "      <th>passage</th>\n",
       "      <th>relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218534</th>\n",
       "      <td>1007691</td>\n",
       "      <td>7251254</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>Direct method allocates each service departmen...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950916</th>\n",
       "      <td>1089945</td>\n",
       "      <td>7079883</td>\n",
       "      <td>the __________ test is a quick and dirty test ...</td>\n",
       "      <td>• The Smell Test is familiar ground in most bu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539660</th>\n",
       "      <td>1007691</td>\n",
       "      <td>423230</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>IT Service (ITILv3): A Service provided to one...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612051</th>\n",
       "      <td>1007691</td>\n",
       "      <td>994382</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>All UK telephone numbers beginning with the di...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026153</th>\n",
       "      <td>1007691</td>\n",
       "      <td>3941750</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>Respite (Out-of-Home) Services [edit]. Respite...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431189</th>\n",
       "      <td>1007691</td>\n",
       "      <td>5146501</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>The Department offers service coordination and...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197484</th>\n",
       "      <td>1007691</td>\n",
       "      <td>5904987</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>If you are a delinquent juror who has been ins...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922032</th>\n",
       "      <td>1007691</td>\n",
       "      <td>5220119</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>There are different types of customer service ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705667</th>\n",
       "      <td>1007691</td>\n",
       "      <td>7088169</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>Us Postal Service Customer Service Phone Numbe...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654277</th>\n",
       "      <td>1007691</td>\n",
       "      <td>3743546</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>A Sub-contractor is liable to pay Service Tax ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qid      pid                                            queries  \\\n",
       "218534   1007691  7251254  when allocating service department costs, the ...   \n",
       "950916   1089945  7079883  the __________ test is a quick and dirty test ...   \n",
       "539660   1007691   423230  when allocating service department costs, the ...   \n",
       "612051   1007691   994382  when allocating service department costs, the ...   \n",
       "1026153  1007691  3941750  when allocating service department costs, the ...   \n",
       "...          ...      ...                                                ...   \n",
       "431189   1007691  5146501  when allocating service department costs, the ...   \n",
       "197484   1007691  5904987  when allocating service department costs, the ...   \n",
       "922032   1007691  5220119  when allocating service department costs, the ...   \n",
       "705667   1007691  7088169  when allocating service department costs, the ...   \n",
       "654277   1007691  3743546  when allocating service department costs, the ...   \n",
       "\n",
       "                                                   passage  relevancy  \n",
       "218534   Direct method allocates each service departmen...        1.0  \n",
       "950916   • The Smell Test is familiar ground in most bu...        1.0  \n",
       "539660   IT Service (ITILv3): A Service provided to one...        0.0  \n",
       "612051   All UK telephone numbers beginning with the di...        0.0  \n",
       "1026153  Respite (Out-of-Home) Services [edit]. Respite...        0.0  \n",
       "...                                                    ...        ...  \n",
       "431189   The Department offers service coordination and...        0.0  \n",
       "197484   If you are a delinquent juror who has been ins...        0.0  \n",
       "922032   There are different types of customer service ...        0.0  \n",
       "705667   Us Postal Service Customer Service Phone Numbe...        0.0  \n",
       "654277   A Sub-contractor is liable to pay Service Tax ...        0.0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_list_df.sort_values(by=['relevancy'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sharing-chile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>queries</th>\n",
       "      <th>passage</th>\n",
       "      <th>relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218534</th>\n",
       "      <td>1007691</td>\n",
       "      <td>7251254</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>Direct method allocates each service departmen...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076853</th>\n",
       "      <td>1007691</td>\n",
       "      <td>7251259</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>The direct method is the most widely-used meth...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95986</th>\n",
       "      <td>1007691</td>\n",
       "      <td>7251251</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>service department provides a large amount of ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95987</th>\n",
       "      <td>1007691</td>\n",
       "      <td>7251253</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>The rows sum to 100%, so that all services pro...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831065</th>\n",
       "      <td>1007691</td>\n",
       "      <td>7251255</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>The most defensible sequence is to start with ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793681</th>\n",
       "      <td>1007691</td>\n",
       "      <td>4814576</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>Service Members | Veterans | Both. Military On...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063650</th>\n",
       "      <td>1007691</td>\n",
       "      <td>6395207</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>that hospital emergency department services ar...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212436</th>\n",
       "      <td>1007691</td>\n",
       "      <td>6872353</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>Yelp Customer Service customer service phone n...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415429</th>\n",
       "      <td>1007691</td>\n",
       "      <td>4114248</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>A service fee, service charge, or surcharge is...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654277</th>\n",
       "      <td>1007691</td>\n",
       "      <td>3743546</td>\n",
       "      <td>when allocating service department costs, the ...</td>\n",
       "      <td>A Sub-contractor is liable to pay Service Tax ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qid      pid                                            queries  \\\n",
       "218534   1007691  7251254  when allocating service department costs, the ...   \n",
       "1076853  1007691  7251259  when allocating service department costs, the ...   \n",
       "95986    1007691  7251251  when allocating service department costs, the ...   \n",
       "95987    1007691  7251253  when allocating service department costs, the ...   \n",
       "831065   1007691  7251255  when allocating service department costs, the ...   \n",
       "...          ...      ...                                                ...   \n",
       "793681   1007691  4814576  when allocating service department costs, the ...   \n",
       "1063650  1007691  6395207  when allocating service department costs, the ...   \n",
       "212436   1007691  6872353  when allocating service department costs, the ...   \n",
       "415429   1007691  4114248  when allocating service department costs, the ...   \n",
       "654277   1007691  3743546  when allocating service department costs, the ...   \n",
       "\n",
       "                                                   passage  relevancy  \n",
       "218534   Direct method allocates each service departmen...        1.0  \n",
       "1076853  The direct method is the most widely-used meth...        0.0  \n",
       "95986    service department provides a large amount of ...        0.0  \n",
       "95987    The rows sum to 100%, so that all services pro...        0.0  \n",
       "831065   The most defensible sequence is to start with ...        0.0  \n",
       "...                                                    ...        ...  \n",
       "793681   Service Members | Veterans | Both. Military On...        0.0  \n",
       "1063650  that hospital emergency department services ar...        0.0  \n",
       "212436   Yelp Customer Service customer service phone n...        0.0  \n",
       "415429   A service fee, service charge, or surcharge is...        0.0  \n",
       "654277   A Sub-contractor is liable to pay Service Tax ...        0.0  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "oriented-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_IDCG(ranking_list_df):\n",
    "    ranking_list_df_sorted = ranking_list_df.sort_values(by=['relevancy'], ascending=False)\n",
    "#     ranking_list_df_sorted = ranking_list_df.reset_index(drop=True, inplace=False)\n",
    "    ranking_list_df_sorted = ranking_list_df_sorted.reset_index().reindex(ranking_list_df_sorted.columns, axis=1)\n",
    "    ideal_discounted_gain_sum = 0\n",
    "    for idx, row in ranking_list_df_sorted.iterrows():\n",
    "        index = idx + 1\n",
    "        relevance_score = row['relevancy']\n",
    "        gain = 2 ** relevance_score - 1\n",
    "        discounted_gain = gain / math.log2(index + 1)\n",
    "        ideal_discounted_gain_sum += discounted_gain\n",
    "    return ideal_discounted_gain_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hollywood-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NDCG(ranking_list_df):\n",
    "    ranking_list_df = ranking_list_df.reset_index(drop=True, inplace=False)\n",
    "    discounted_gain_sum = 0\n",
    "    for idx, row in ranking_list_df.iterrows():\n",
    "        index = idx + 1\n",
    "        relevance_score = row['relevancy']\n",
    "        gain = 2 ** relevance_score - 1\n",
    "        discounted_gain = gain / math.log2(index + 1)\n",
    "        discounted_gain_sum += discounted_gain\n",
    "    IDCG = get_IDCG(ranking_list_df)\n",
    "    \n",
    "    nDCG = discounted_gain_sum / IDCG\n",
    "    return nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "lonely-seminar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7841802768331765"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_NDCG(ranking_list_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-freedom",
   "metadata": {},
   "source": [
    "# Subtask 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "conservative-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:1000] # 일단 1000개만 해봄\n",
    "validation_data = validation_data[:1000] # 일단 1000개만 해봄"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-crash",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "minus-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# passages = validation_data.passage.values[:1000]\n",
    "# validation_data_temp = validation_data[:1000]\n",
    "# validation_data_temp['passage_cleaned']=validation_data_temp.passage.apply(lambda x: preprocessing(x))\n",
    "# validation_data_temp['queries_cleaned']=validation_data_temp.queries.apply(lambda x: preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "academic-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['passage_cleaned']=train_data.passage.apply(lambda x: preprocessing(x))\n",
    "train_data['query_cleaned']=train_data.queries.apply(lambda x: preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "seasonal-adrian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th>queries</th>\n",
       "      <th>passage</th>\n",
       "      <th>relevancy</th>\n",
       "      <th>passage_cleaned</th>\n",
       "      <th>queries_cleaned</th>\n",
       "      <th>query_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>188714</td>\n",
       "      <td>1000052</td>\n",
       "      <td>foods and supplements to lower blood sugar</td>\n",
       "      <td>Watch portion sizes: ■ Even healthy foods will...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[watch, portion, size, even, healthy, foods, c...</td>\n",
       "      <td>[foods, supplement, lower, blood, sugar]</td>\n",
       "      <td>[foods, supplement, lower, blood, sugar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>995526</td>\n",
       "      <td>1000094</td>\n",
       "      <td>where is the federal penitentiary in ind</td>\n",
       "      <td>It takes THOUSANDS of Macy's associates to bri...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[take, thousands, macy, associate, bring, magi...</td>\n",
       "      <td>[federal, penitentiary, ind]</td>\n",
       "      <td>[federal, penitentiary, ind]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660957</td>\n",
       "      <td>1000115</td>\n",
       "      <td>what foods are good if you have gout?</td>\n",
       "      <td>The good news is that you will discover what g...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[good, news, discover, go, action, spur, narro...</td>\n",
       "      <td>[foods, good, gout]</td>\n",
       "      <td>[foods, good, gout]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>837202</td>\n",
       "      <td>1000252</td>\n",
       "      <td>what is the nutritional value of oatmeal</td>\n",
       "      <td>Oats make an easy, balanced breakfast. One cup...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[oats, make, easy, balance, breakfast, one, cu...</td>\n",
       "      <td>[nutritional, value, oatmeal]</td>\n",
       "      <td>[nutritional, value, oatmeal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130825</td>\n",
       "      <td>1000268</td>\n",
       "      <td>definition for daring</td>\n",
       "      <td>Such a requirement would have three desirable ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[requirement, would, three, desirable, consequ...</td>\n",
       "      <td>[definition, dare]</td>\n",
       "      <td>[definition, dare]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>400803</td>\n",
       "      <td>1016366</td>\n",
       "      <td>is a revocable trust a separate legal entity</td>\n",
       "      <td>The income and deductions of the trust are rep...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[income, deductions, trust, report, income, ta...</td>\n",
       "      <td>[revocable, trust, separate, legal, entity]</td>\n",
       "      <td>[revocable, trust, separate, legal, entity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>400803</td>\n",
       "      <td>1016370</td>\n",
       "      <td>is a revocable trust a separate legal entity</td>\n",
       "      <td>A grantor trust is a living revocable trust in...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[grantor, trust, live, revocable, trust, grant...</td>\n",
       "      <td>[revocable, trust, separate, legal, entity]</td>\n",
       "      <td>[revocable, trust, separate, legal, entity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>544319</td>\n",
       "      <td>1016449</td>\n",
       "      <td>weather in gig harbor, wa</td>\n",
       "      <td>The gig economy is the collection of markets t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[gig, economy, collection, market, match, prov...</td>\n",
       "      <td>[weather, gig, harbor, wa]</td>\n",
       "      <td>[weather, gig, harbor, wa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>617246</td>\n",
       "      <td>1016466</td>\n",
       "      <td>what decisions rules can determine upheld or d...</td>\n",
       "      <td>To claim a tax deduction for business mileage,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[claim, tax, deduction, business, mileage, sel...</td>\n",
       "      <td>[decisions, rule, determine, uphold, dismiss, ...</td>\n",
       "      <td>[decisions, rule, determine, uphold, dismiss, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1097069</td>\n",
       "      <td>1016480</td>\n",
       "      <td>average gas costs in kentucky</td>\n",
       "      <td>Over the next 30 months, however, the average ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[next, months, however, average, cost, clients...</td>\n",
       "      <td>[average, gas, cost, kentucky]</td>\n",
       "      <td>[average, gas, cost, kentucky]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         qid      pid                                            queries  \\\n",
       "0     188714  1000052         foods and supplements to lower blood sugar   \n",
       "1     995526  1000094           where is the federal penitentiary in ind   \n",
       "2     660957  1000115              what foods are good if you have gout?   \n",
       "3     837202  1000252           what is the nutritional value of oatmeal   \n",
       "4     130825  1000268                              definition for daring   \n",
       "..       ...      ...                                                ...   \n",
       "995   400803  1016366       is a revocable trust a separate legal entity   \n",
       "996   400803  1016370       is a revocable trust a separate legal entity   \n",
       "997   544319  1016449                          weather in gig harbor, wa   \n",
       "998   617246  1016466  what decisions rules can determine upheld or d...   \n",
       "999  1097069  1016480                      average gas costs in kentucky   \n",
       "\n",
       "                                               passage  relevancy  \\\n",
       "0    Watch portion sizes: ■ Even healthy foods will...        0.0   \n",
       "1    It takes THOUSANDS of Macy's associates to bri...        0.0   \n",
       "2    The good news is that you will discover what g...        0.0   \n",
       "3    Oats make an easy, balanced breakfast. One cup...        0.0   \n",
       "4    Such a requirement would have three desirable ...        0.0   \n",
       "..                                                 ...        ...   \n",
       "995  The income and deductions of the trust are rep...        0.0   \n",
       "996  A grantor trust is a living revocable trust in...        0.0   \n",
       "997  The gig economy is the collection of markets t...        0.0   \n",
       "998  To claim a tax deduction for business mileage,...        0.0   \n",
       "999  Over the next 30 months, however, the average ...        0.0   \n",
       "\n",
       "                                       passage_cleaned  \\\n",
       "0    [watch, portion, size, even, healthy, foods, c...   \n",
       "1    [take, thousands, macy, associate, bring, magi...   \n",
       "2    [good, news, discover, go, action, spur, narro...   \n",
       "3    [oats, make, easy, balance, breakfast, one, cu...   \n",
       "4    [requirement, would, three, desirable, consequ...   \n",
       "..                                                 ...   \n",
       "995  [income, deductions, trust, report, income, ta...   \n",
       "996  [grantor, trust, live, revocable, trust, grant...   \n",
       "997  [gig, economy, collection, market, match, prov...   \n",
       "998  [claim, tax, deduction, business, mileage, sel...   \n",
       "999  [next, months, however, average, cost, clients...   \n",
       "\n",
       "                                       queries_cleaned  \\\n",
       "0             [foods, supplement, lower, blood, sugar]   \n",
       "1                         [federal, penitentiary, ind]   \n",
       "2                                  [foods, good, gout]   \n",
       "3                        [nutritional, value, oatmeal]   \n",
       "4                                   [definition, dare]   \n",
       "..                                                 ...   \n",
       "995        [revocable, trust, separate, legal, entity]   \n",
       "996        [revocable, trust, separate, legal, entity]   \n",
       "997                         [weather, gig, harbor, wa]   \n",
       "998  [decisions, rule, determine, uphold, dismiss, ...   \n",
       "999                     [average, gas, cost, kentucky]   \n",
       "\n",
       "                                         query_cleaned  \n",
       "0             [foods, supplement, lower, blood, sugar]  \n",
       "1                         [federal, penitentiary, ind]  \n",
       "2                                  [foods, good, gout]  \n",
       "3                        [nutritional, value, oatmeal]  \n",
       "4                                   [definition, dare]  \n",
       "..                                                 ...  \n",
       "995        [revocable, trust, separate, legal, entity]  \n",
       "996        [revocable, trust, separate, legal, entity]  \n",
       "997                         [weather, gig, harbor, wa]  \n",
       "998  [decisions, rule, determine, uphold, dismiss, ...  \n",
       "999                     [average, gas, cost, kentucky]  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "aboriginal-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data['passage_cleaned']=validation_data.passage.apply(lambda x: preprocessing(x))\n",
    "validation_data['query_cleaned']=validation_data.queries.apply(lambda x: preprocessing(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-deviation",
   "metadata": {},
   "source": [
    "## Loading word2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "signal-bronze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pre-trained embeddings, each word is represented as a 300 dimensional vector\n",
    "import gensim\n",
    "W2V_PATH=\"../GoogleNews-vectors-negative300.bin\"\n",
    "model_w2v = gensim.models.KeyedVectors.load_word2vec_format(W2V_PATH, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-birmingham",
   "metadata": {},
   "source": [
    "# Embedding documents and queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-setting",
   "metadata": {},
   "source": [
    "## embedding documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-lesson",
   "metadata": {},
   "source": [
    "### training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "listed-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and pad every document to make them of the same size\n",
    "passage_tokenizer=Tokenizer()\n",
    "passage_tokenizer.fit_on_texts(train_data.passage_cleaned)\n",
    "passage_max_length = 128 # document length including padding\n",
    "query_max_length = 64 # query length including padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating embedding matrix, every row is a vector representation from the vocabulary indexed by the tokenizer index. \n",
    "# document_embedding_matrix=np.zeros((passage_vocab_size,300))\n",
    "# for word,i in passage_tokenizer.word_index.items():\n",
    "#     if word in model_w2v:\n",
    "#         document_embedding_matrix[i]=model_w2v[word]\n",
    "# # creating document-word embeddings\n",
    "# train_data_length = tokenized_paded_documents.shape[0]\n",
    "# passage_max_length = 64 # document length including padding\n",
    "# document_word_embeddings_train=np.zeros((train_data_length, passage_max_length,300)) # 64 == padding\n",
    "# for i in range(train_data_length):\n",
    "#     for j in range(passage_max_length): \n",
    "#         document_word_embeddings_train[i][j] = document_embedding_matrix[tokenized_paded_documents[i][j]]\n",
    "# document_word_embeddings_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "foreign-census",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 128, 300)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_length = train_data.shape[0]\n",
    "document_word_embeddings_train=np.zeros((train_data_length, passage_max_length,300)) # 64 == padding\n",
    "passages = train_data.passage_cleaned\n",
    "for i in range(len(passages)):\n",
    "    passage = passages[i]\n",
    "    passage_length = len(passage)\n",
    "    for j in range(passage_length): \n",
    "        word = passage[j]\n",
    "        if word in model_w2v:\n",
    "            document_word_embeddings_train[i][j] = model_w2v[word]\n",
    "document_word_embeddings_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "desperate-breakdown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_vector_list_length = document_word_embeddings_train.shape[0]\n",
    "average_document_vectors_train = np.zeros((average_vector_list_length,300))\n",
    "for i in range(average_vector_list_length):\n",
    "    average_document_vectors_train[i] = np.mean(document_word_embeddings_train[i], axis=0)\n",
    "average_document_vectors_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-entity",
   "metadata": {},
   "source": [
    "### validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "exciting-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and pad every document to make them of the same size\n",
    "passage_tokenizer=Tokenizer()\n",
    "passage_tokenizer.fit_on_texts(validation_data.passage_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "indian-office",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 64, 300)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # creating embedding matrix, every row is a vector representation from the vocabulary indexed by the tokenizer index. \n",
    "# document_embedding_matrix=np.zeros((passage_vocab_size,300))\n",
    "# for word,i in passage_tokenizer.word_index.items():\n",
    "#     if word in model_w2v:\n",
    "#         document_embedding_matrix[i]=model_w2v[word]\n",
    "# # creating document-word embeddings\n",
    "# document_word_embeddings_val=np.zeros((len(tokenized_paded_documents),64,300))\n",
    "# for i in range(len(tokenized_paded_documents)):\n",
    "#     for j in range(len(tokenized_paded_documents[0])):\n",
    "#         document_word_embeddings_val[i][j]=document_embedding_matrix[tokenized_paded_documents[i][j]]\n",
    "# document_word_embeddings_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "institutional-improvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 128, 300)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data_length = validation_data.shape[0]\n",
    "document_word_embeddings_val=np.zeros((validation_data_length, passage_max_length,300)) # 64 == padding\n",
    "passages = validation_data.passage_cleaned\n",
    "for i in range(len(passages)):\n",
    "    passage = passages[i]\n",
    "    passage_length = len(passage)\n",
    "    for j in range(passage_length): \n",
    "        word = passage[j]\n",
    "        if word in model_w2v:\n",
    "            document_word_embeddings_val[i][j] = model_w2v[word]\n",
    "document_word_embeddings_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "extra-popularity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_vector_list_length = document_word_embeddings_val.shape[0]\n",
    "average_document_vectors_val = np.zeros((average_vector_list_length,300))\n",
    "for i in range(average_vector_list_length):\n",
    "    average_document_vectors_val[i] = np.mean(document_word_embeddings_val[i], axis=0)\n",
    "average_document_vectors_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-police",
   "metadata": {},
   "source": [
    "## embedding quries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-contrary",
   "metadata": {},
   "source": [
    "### training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "matched-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and pad every document to make them of the same size\n",
    "query_tokenizer=Tokenizer()\n",
    "query_tokenizer.fit_on_texts(train_data.queries_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "minimal-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating embedding matrix, every row is a vector representation from the vocabulary indexed by the tokenizer index. \n",
    "# query_embedding_matrix=np.zeros((query_vocab_size,300))\n",
    "# for word,i in query_tokenizer.word_index.items():\n",
    "#     if word in model_w2v:\n",
    "#         query_embedding_matrix[i]=model_w2v[word]\n",
    "# # creating query-word embeddings\n",
    "# query_word_embeddings_train=np.zeros((len(tokenized_paded_quries),32,300))\n",
    "# for i in range(len(tokenized_paded_quries)):\n",
    "#     for j in range(len(tokenized_paded_quries[0])):\n",
    "#         query_word_embeddings_train[i][j]=query_embedding_matrix[tokenized_paded_quries[i][j]]\n",
    "# query_word_embeddings_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "frank-isaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 64, 300)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_length = train_data.shape[0]\n",
    "query_word_embeddings_train=np.zeros((train_data_length, query_max_length,300)) # 64 == padding\n",
    "queries = train_data.query_cleaned\n",
    "for i in range(len(queries)):\n",
    "    query = queries[i]\n",
    "    query_length = len(query)\n",
    "    for j in range(query_length): \n",
    "        word = query[j]\n",
    "        if word in model_w2v:\n",
    "            query_word_embeddings_train[i][j] = model_w2v[word]\n",
    "query_word_embeddings_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "timely-beaver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_vector_list_length = query_word_embeddings_train.shape[0]\n",
    "average_query_vectors_train = np.zeros((average_vector_list_length,300))\n",
    "for i in range(average_vector_list_length):\n",
    "    average_query_vectors_train[i] = np.mean(query_word_embeddings_train[i], axis=0)\n",
    "average_query_vectors_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-shape",
   "metadata": {},
   "source": [
    "### validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "constitutional-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and pad every document to make them of the same size\n",
    "query_tokenizer=Tokenizer()\n",
    "query_tokenizer.fit_on_texts(validation_data.queries_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cosmetic-remove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 32, 300)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # creating embedding matrix, every row is a vector representation from the vocabulary indexed by the tokenizer index. \n",
    "# query_embedding_matrix=np.zeros((query_vocab_size,300))\n",
    "# for word,i in query_tokenizer.word_index.items():\n",
    "#     if word in model_w2v:\n",
    "#         query_embedding_matrix[i]=model_w2v[word]\n",
    "# # creating query-word embeddings\n",
    "# query_word_embeddings_val=np.zeros((len(tokenized_paded_quries),32,300))\n",
    "# for i in range(len(tokenized_paded_quries)):\n",
    "#     for j in range(len(tokenized_paded_quries[0])):\n",
    "#         query_word_embeddings_val[i][j]=query_embedding_matrix[tokenized_paded_quries[i][j]]\n",
    "# query_word_embeddings_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "sapphire-sister",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 64, 300)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data_length = validation_data.shape[0]\n",
    "query_word_embeddings_val=np.zeros((validation_data_length, query_max_length,300)) # 64 == padding\n",
    "queries = validation_data.query_cleaned\n",
    "for i in range(len(queries)):\n",
    "    query = queries[i]\n",
    "    query_length = len(query)\n",
    "    for j in range(query_length): \n",
    "        word = query[j]\n",
    "        if word in model_w2v:\n",
    "            query_word_embeddings_val[i][j] = model_w2v[word]\n",
    "query_word_embeddings_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "superior-statement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_vector_list_length = query_word_embeddings_val.shape[0]\n",
    "average_query_vectors_val = np.zeros((average_vector_list_length,300))\n",
    "for i in range(average_vector_list_length):\n",
    "    average_query_vectors_val[i] = np.mean(query_word_embeddings_val[i], axis=0)\n",
    "average_query_vectors_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "rural-durham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 300)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_word_embeddings_val[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "accompanied-mayor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_word_embeddings_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fourth-oregon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(query_word_embeddings_val[0], axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-bahrain",
   "metadata": {},
   "source": [
    "## creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "infectious-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim_formula(a, b):\n",
    "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "vertical-notice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.zeros((average_query_vectors_train.shape[0], 1))\n",
    "x_train_val = np.zeros((average_query_vectors_val.shape[0], 1))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "developed-calculator",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wen\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(x_train.shape[0]):\n",
    "    query_vector = average_query_vectors_train[i]\n",
    "    passage_vector = average_document_vectors_train[i]\n",
    "    x_train[i] = cosine_sim_formula(query_vector, passage_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "second-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train_val)):\n",
    "    query_vector = average_query_vectors_val[i]\n",
    "    passage_vector = average_document_vectors_val[i]\n",
    "    x_train_val[i] = cosine_sim_formula(query_vector, passage_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "opened-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data.relevancy.values\n",
    "y_train_val = validation_data.relevancy.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-chinese",
   "metadata": {},
   "source": [
    "## Logisitc Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-telescope",
   "metadata": {},
   "source": [
    "## 현재 문제 \n",
    "1. 딥러닝 과제처럼, 한 data씩 처리 할건지, 아니면 인터넷 예제처럼 모든 value를 metrics 에 넣어서 한번에 처리할건지\n",
    "2. 딥러닝 과제처럼 처리했을 경우, gradient descent function은 무엇인지, 인터넷 예제처럼 했을 때도, 인터넷에 있는 gradient descent function 이 어떻게 derive 됬는지 알기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "racial-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "\n",
    "    def __init__(self, learning_rate=0.001, epoch=500):\n",
    "        self.lr = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.loss_train = None\n",
    "        self.loss_val = None\n",
    "\n",
    "        self.acc_train = None\n",
    "        self.train_correct = None\n",
    "        self.val_correct = None\n",
    "        \n",
    "        self.losslist_train = []\n",
    "        self.losslist_val = []\n",
    "        self.acclist_train = []\n",
    "        self.acclist_val = []\n",
    "    \n",
    "\n",
    "        \n",
    "    def fit(self, trainxs, trainys, trainxs_val, trainys_val):\n",
    "        n_samples, n_features = trainxs.shape\n",
    "\n",
    "        # init parameters\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        # gradient descent\n",
    "        for _ in range(self.epoch):\n",
    "            idx = self.shuffleIdx(trainxs.shape[0])\n",
    "            X = trainxs[idx]\n",
    "            Y = trainys[idx]\n",
    "            \n",
    "            \n",
    "            self.loss_train = 0\n",
    "            self.loss_val = 0\n",
    "\n",
    "            self.acc_train = 0\n",
    "            self.train_correct = 0\n",
    "            self.val_correct = 0\n",
    "            \n",
    "            for i in range(trainxs.shape[0]):\n",
    "                x = X[i]\n",
    "                y = Y[i]\n",
    "                # approximate output variable (y) with linear combination of weights and x, plus bias\n",
    "                linear_equation = np.dot(x, self.weights) + self.bias\n",
    "                # apply sigmoid function\n",
    "                prediction = self.sigmoid(linear_equation)\n",
    "                print(\"prediction:\", prediction)\n",
    "                \n",
    "                if prediction >= 0.5:\n",
    "                    yprime = 1\n",
    "                else:\n",
    "                    yprime = 0\n",
    "\n",
    "                if yprime == y:\n",
    "                    self.train_correct += 1\n",
    "\n",
    "                self.loss_train += self.loss_function(y, prediction)\n",
    "\n",
    "                # compute gradients\n",
    "                dw = (1 / n_samples) * np.dot(X.T, (prediction - y)) #derivative w.r.t weights\n",
    "                db = (1 / n_samples) * np.sum(prediction - y)  #derivative w.r.t bias\n",
    "                # update parameters\n",
    "                self.weights -= self.lr * dw\n",
    "                self.bias -= self.lr * db\n",
    "\n",
    "                 # COMPUTING LOSS AND ACCURACY OF VALIDATION SET\n",
    "                if (i < trainxs_val.shape[0]):\n",
    "                    val_x = trainxs_val[i]\n",
    "                    val_y = trainys_val[i]\n",
    "                    linear_equation = np.dot(val_x, self.weights) + self.bias\n",
    "                    prediction = self.sigmoid(linear_equation)\n",
    "\n",
    "                    if prediction  >= 0.5:\n",
    "                        yprime = 1\n",
    "                    else:\n",
    "                        yprime = 0\n",
    "\n",
    "                    if yprime == val_y:\n",
    "                        self.val_correct += 1\n",
    "\n",
    "                    self.loss_val += ((val_y - prediction)**2)/2\n",
    "\n",
    "            self.loss_train = self.loss_train/n_samples\n",
    "            self.losslist_train.append(self.loss_train)\n",
    "\n",
    "            self.loss_val = self.loss_val/(n_samples_val)\n",
    "            self.losslist_val.append(self.loss_val)\n",
    "\n",
    "            self.train_correct = self.train_correct/n_samples\n",
    "            self.acclist_train.append(self.train_correct)\n",
    "\n",
    "            self.val_correct = self.val_correct/(n_samples_val)\n",
    "            self.acclist_val.append(self.val_correct)\n",
    "\n",
    "            \n",
    "    def shuffleIdx(self, n):\n",
    "        rng = default_rng()\n",
    "        rand_idx = rng.permutation(n)\n",
    "        return rand_idx\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_equation = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.sigmoid(linear_equation)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return np.array(y_predicted_cls)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def loss_function(self, y, prediction):\n",
    "        return -log((1 - prediction)**(1 - y)) - log(prediction**y)\n",
    "    \n",
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "underlying-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=[i in range(1000)]\n",
    "accuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "dressed-aquatic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 0.5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (1,1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-41adfa3230d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# predictions = regressor.predict(xtest)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-155-2ba43462813b>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, trainxs, trainys, trainxs_val, trainys_val)\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#derivative w.r.t bias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[1;31m# update parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (1,) doesn't match the broadcast shape (1,1000)"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(learning_rate=0.0001, epoch=500)\n",
    "lr.fit(x_train, y_train, x_train_val, y_train_val)\n",
    "# predictions = regressor.predict(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "super-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "gross-interference",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.024742149807413506"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-orlando",
   "metadata": {},
   "source": [
    "# Subtask 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "handed-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import DMatrix,train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "christian-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_rank_params1 ={    \n",
    "#     'booster' : 'gbtree',\n",
    "#     'eta': 0.1,\n",
    "#     'gamma' : 1.0 ,\n",
    "#     'min_child_weight' : 0.1,\n",
    "#     'objective' : 'rank:pairwise',\n",
    "#     'eval_metric' : 'merror',\n",
    "#     'max_depth' : 6,\n",
    "#     'num_boost_round':10,\n",
    "#     'save_period' : 0 \n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'bst:max_depth':2, \n",
    "    'bst:eta':1, 'silent':1, \n",
    "    'objective':'rank:pairwise',\n",
    "    'nthread':4,\n",
    "    'eval_metric':'ndcg'\n",
    "}\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "supported-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate training dataset\n",
    "n_group=2\n",
    "n_choice=3  \n",
    "dtrain=np.random.uniform(0,100,[n_group*n_choice,2])    \n",
    "#numpy.random.choice(a, size=None, replace=True, p=None)\n",
    "dtarget=np.array([np.random.choice([0,1,2],3,False) for i in range(n_group)]).flatten()\n",
    "#n_group用于表示从前到后每组各自有多少样本，前提是样本中各组是连续的，[3，3]表示一共6条样本中前3条是第一组，后3条是第二组\n",
    "dgroup= np.array([n_choice for i in range(n_group)]).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acute-citizen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 2, 0, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "blocked-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76.13114507, 72.51374314],\n",
       "       [56.71265772, 39.39356257],\n",
       "       [67.39643181, 34.78308006],\n",
       "       [98.54392286, 32.87569918],\n",
       "       [18.00958146, 23.27901363],\n",
       "       [79.99957957, 23.68170943]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "needed-christopher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dedicated-locking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate Train data, very import here !\n",
    "xgbTrain = DMatrix(dtrain, label = dtarget)\n",
    "xgbTrain.set_group(dgroup)\n",
    "\n",
    "# generate eval data\n",
    "dtrain_eval=np.random.uniform(0,100,[n_group*n_choice,2])        \n",
    "xgbTrain_eval = DMatrix(dtrain_eval, label = dtarget)\n",
    "xgbTrain_eval .set_group(dgroup)\n",
    "evallist  = [(xgbTrain,'train'),(xgbTrain_eval, 'eval')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "# xgb_rank_params1加上 evals 这个参数会报错，还没找到原因\n",
    "# rankModel = train(xgb_rank_params1,xgbTrain,num_boost_round=10)\n",
    "rankModel = train(xgb_rank_params2,xgbTrain,num_boost_round=20,evals=evallist)\n",
    "\n",
    "#test dataset\n",
    "dtest=np.random.uniform(0,100,[n_group*n_choice,2])    \n",
    "dtestgroup=np.array([n_choice for i in range(n_group)]).flatten()\n",
    "xgbTest = DMatrix(dtest)\n",
    "xgbTest.set_group(dgroup)\n",
    "\n",
    "# test\n",
    "print(rankModel.predict( xgbTest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
